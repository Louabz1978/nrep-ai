{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Ig5yyaSOji"
      },
      "source": [
        "# ***MARKET CLASSIFICATION MODEL***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARZ3NPipqSJ2"
      },
      "source": [
        "This model will be used to classify the current market into three classes:\n",
        "*   Buyers Market\n",
        "*   Sellers Market\n",
        "*   Even Market\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHuiZTy6SB3N"
      },
      "source": [
        "# ***MARKET CLASSIFICATION MODEL FEATURES***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb7zXkQVWDCL"
      },
      "source": [
        "Notation:\n",
        "*   (IMP): Important Feature\n",
        "\n",
        "The following features will be used:\n",
        "*   Activity Ratios (Quarterly):\n",
        "    *   (IMP) New listings ratio: new_active_listings / total_properties\n",
        "    *   (IMP) Absorption rate: closed_sales / active_listings\n",
        "    *   (IMP) Pending conversion rate: pending_to_closed / total_pending\n",
        "    *   Back-to-market rate: back_to_market / total_pending\n",
        "    *   Off-market withdrawal rate: off_market / total_active\n",
        "*   Velocity Metrics:\n",
        "    *   Average days on market: sum(days_active) / closed_sales\n",
        "    *   Pending duration: sum(days_pending) / closed_sales\n",
        "    *   (IMP) Market turnover: total_status_changes / total_properties\n",
        "*   Supply-Demand Indicators:\n",
        "    *   Inventory months: active_listings / (closed_sales / 3_months)\n",
        "    *   (IMP) Competition index: pending_listings / active_listings\n",
        "    *   (IMP) Market pressure: (new_listings - closed_sales) / new_listings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vm8YtlOeiDl"
      },
      "source": [
        "# ***EXPLAINING THE VARIABLES***\n",
        "\n",
        "**Activity Ratios**\n",
        "\n",
        "*   **New Listings Ratio:** new_active_listings / total_properties\n",
        "\n",
        "    **Variables:**\n",
        "      *   *new_active_listings:* Count of properties that entered \"Active\" status for the first time during the quarter\n",
        "      *   *total_properties:* Total unique properties with any activity in the quarter\n",
        "\n",
        "    **Purpose:** Measures fresh inventory entering the market relative to overall market size\n",
        "\n",
        "    <br>\n",
        "\n",
        "*   **Absorption Rate:** closed_sales / active_listings\n",
        "\n",
        "    **Variables:**\n",
        "      *   *closed_sales:* Number of properties that changed from any status to \"Closed\" during the quarter\n",
        "      *   *active_listings:* Average number of properties in \"Active\" status during the quarter\n",
        "\n",
        "    **Purpose:** Indicates how quickly the market absorbs available inventory\n",
        "    \n",
        "    <br>\n",
        "\n",
        "*   **Pending Conversion Rate:** pending_to_closed / total_pending\n",
        "\n",
        "    **Variables:**\n",
        "      *   *pending_to_closed:* Properties that successfully moved from \"Pending\" to \"Closed\" status\n",
        "      *   *total_pending:* All properties that were in \"Pending\" status at any point during the quarter\n",
        "\n",
        "    **Purpose:** Measures deal completion success rate\n",
        "\n",
        "    <br>\n",
        "\n",
        "*   **Back-to-Market Rate:** back_to_market / total_pending\n",
        "\n",
        "    **Variables:**\n",
        "      *   *back_to_market:* Properties that moved from \"Pending\" back to \"Active\" status (failed deals)\n",
        "      *   *total_pending:* All properties that were in \"Pending\" status at any point during the quarter\n",
        "\n",
        "    **Purpose:** Indicates market instability and deal failure rates\n",
        "\n",
        "    <br>\n",
        "\n",
        "*   **Off-Market Withdrawal Rate:** off_market / total_active\n",
        "\n",
        "    **Variables:**\n",
        "      *   *off_market:* Properties that moved from \"Active\" to \"Off Market\" status (withdrawn without selling)\n",
        "      *   *total_active:* Total properties that were active during the quarter\n",
        "\n",
        "    **Purpose:** Shows seller confidence in the current market conditions\n",
        "\n",
        "    <br>\n",
        "\n",
        "**Velocity Metrics**\n",
        "\n",
        "*   **Average Days on Market:** sum(days_active) / closed_sales\n",
        "\n",
        "    **Variables:**\n",
        "      *   *days_active:* total days properties spent in \"Active\" status before selling\n",
        "      *   *closed_sales:* Number of properties that successfully closed\n",
        "\n",
        "    **Purpose:** Measures how quickly properties sell, indicating market heat\n",
        "\n",
        "    <br>\n",
        "\n",
        "*   **Pending Duration:** sum(days_pending) / closed_sales\n",
        "\n",
        "    **Variables:**\n",
        "      *   *days_pending:* Total days properties spent in \"Pending\" status before closing\n",
        "      *   *closed_sales:* Number of properties that successfully closed\n",
        "\n",
        "    **Purpose:** Indicates transaction complexity and financing conditions\n",
        "\n",
        "    <br>\n",
        "\n",
        "*   **Market Turnover:** total_status_changes / total_properties\n",
        "\n",
        "    **Variables:**\n",
        "      *   *total_status_changes:* Sum of all status transitions (Active‚ÜíPending, Pending‚ÜíClosed, etc.)\n",
        "      *   *total_properties:* Total unique properties in the dataset\n",
        "\n",
        "    **Purpose:** Measures overall market activity and dynamism\n",
        "\n",
        "    <br>\n",
        "\n",
        "**Supply-Demand Indicators**\n",
        "*   **Inventory Months:** active_listings / (closed_sales / 3_months)\n",
        "\n",
        "    **Variables:**\n",
        "      *   *active_listings:* Current count of properties in \"Active\" status at quarter-end\n",
        "      *   *closed_sales:* Number of sales completed in the quarter\n",
        "      *   *3_months:* equals 3\n",
        "\n",
        "    **Purpose:** Shows how many months it would take to sell current inventory at current pace\n",
        "\n",
        "    <br>\n",
        "\n",
        "*   **Competition Index:** pending_listings / active_listings\n",
        "\n",
        "    **Variables:**\n",
        "      *   *pending_listings:* Properties currently in \"Pending\" status\n",
        "      *   *active_listings:* Properties currently in \"Active\" status\n",
        "\n",
        "    **Purpose:** Indicates buyer competition intensity\n",
        "\n",
        "    <br>\n",
        "\n",
        "*   **Market Pressure:** (new_listings - closed_sales) / new_listings\n",
        "\n",
        "    **Variables:**\n",
        "      *   *new_listings:* Properties newly entered to market during quarter\n",
        "      *   *closed_sales:* Properties that closed during quarter\n",
        "\n",
        "    **Purpose:** Shows whether supply is increasing or decreasing relative to demand\n",
        "\n",
        "    <br>\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "Transitions\n",
        "*   **Active‚ÜíPending:** Properties moving under contract\n",
        "*   **Pending‚ÜíClosed:** Successful transactions\n",
        "*   **Pending‚ÜíActive:** Failed contracts returning to market\n",
        "*   **Active‚ÜíOff Market:** Withdrawn listings\n",
        "*   **Off Market‚ÜíActive:** Re-listed properties\n",
        "\n",
        "These transitions are counted and timed to create velocity and success rate metrics.\n",
        "We are using only the most recent quarterly periods so we could use rolling averages to include the older quarterlies values in the decision making while giving them less importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxBT7dZky6lW"
      },
      "source": [
        "# ***CREATING THE MODEL***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUO-SZKYyFYM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAJkqUI_zDm0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HousingMarketPredictor:\n",
        "    \"\"\"\n",
        "    Complete XGBoost model for housing market condition prediction\n",
        "    Classifies markets as: 0=Buyers Market, 1=Even Market, 2=Sellers Market\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.feature_names = []\n",
        "        self.is_fitted = False\n",
        "\n",
        "    def create_sample_data(self, n_samples=1000):\n",
        "        \"\"\"\n",
        "        Generate realistic sample housing market data\n",
        "        \"\"\"\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Generate base metrics with realistic correlations\n",
        "        data = {}\n",
        "\n",
        "        # Market conditions (0=Buyers, 1=Even, 2=Sellers)\n",
        "        market_conditions = np.random.choice([0, 1, 2], n_samples, p=[0.3, 0.4, 0.3])\n",
        "\n",
        "        # Generate features based on market conditions\n",
        "        for i in range(n_samples):\n",
        "            condition = market_conditions[i]\n",
        "\n",
        "            if condition == 0:  # Buyers Market\n",
        "                # High inventory, low absorption, longer DOM\n",
        "                active_listings = np.random.normal(500, 100)\n",
        "                closed_sales = np.random.normal(80, 20)\n",
        "                days_on_market = np.random.normal(45, 15)\n",
        "                pending_conversion = np.random.normal(0.75, 0.1)\n",
        "                back_to_market_rate = np.random.normal(0.15, 0.05)\n",
        "\n",
        "            elif condition == 1:  # Even Market\n",
        "                # Balanced metrics\n",
        "                active_listings = np.random.normal(300, 50)\n",
        "                closed_sales = np.random.normal(100, 15)\n",
        "                days_on_market = np.random.normal(30, 10)\n",
        "                pending_conversion = np.random.normal(0.85, 0.05)\n",
        "                back_to_market_rate = np.random.normal(0.08, 0.03)\n",
        "\n",
        "            else:  # Sellers Market\n",
        "                # Low inventory, high absorption, quick sales\n",
        "                active_listings = np.random.normal(150, 30)\n",
        "                closed_sales = np.random.normal(120, 25)\n",
        "                days_on_market = np.random.normal(15, 8)\n",
        "                pending_conversion = np.random.normal(0.95, 0.03)\n",
        "                back_to_market_rate = np.random.normal(0.03, 0.02)\n",
        "\n",
        "            # Ensure positive values\n",
        "            active_listings = max(50, active_listings)\n",
        "            closed_sales = max(10, closed_sales)\n",
        "            days_on_market = max(5, days_on_market)\n",
        "            pending_conversion = np.clip(pending_conversion, 0.5, 1.0)\n",
        "            back_to_market_rate = np.clip(back_to_market_rate, 0.01, 0.3)\n",
        "\n",
        "            # Calculate derived features\n",
        "            total_properties = active_listings + closed_sales + np.random.normal(50, 20)\n",
        "            total_properties = max(100, total_properties)\n",
        "\n",
        "            pending_listings = np.random.normal(closed_sales * 0.3, 10)\n",
        "            pending_listings = max(5, pending_listings)\n",
        "\n",
        "            new_listings = np.random.normal(closed_sales * 1.2, 20)\n",
        "            new_listings = max(20, new_listings)\n",
        "\n",
        "            off_market = np.random.normal(active_listings * 0.1, 5)\n",
        "            off_market = max(1, off_market)\n",
        "\n",
        "            data[i] = {\n",
        "                'active_listings': active_listings,\n",
        "                'closed_sales': closed_sales,\n",
        "                'pending_listings': pending_listings,\n",
        "                'new_listings': new_listings,\n",
        "                'off_market': off_market,\n",
        "                'total_properties': total_properties,\n",
        "                'days_on_market': days_on_market,\n",
        "                'pending_conversion_rate': pending_conversion,\n",
        "                'back_to_market_rate': back_to_market_rate,\n",
        "                'market_condition': condition\n",
        "            }\n",
        "\n",
        "        return pd.DataFrame.from_dict(data, orient='index')\n",
        "\n",
        "    def engineer_features(self, df):\n",
        "        \"\"\"\n",
        "        Create all the features we discussed for market prediction\n",
        "        \"\"\"\n",
        "        features_df = df.copy()\n",
        "\n",
        "        # Activity Ratios\n",
        "        features_df['new_listings_ratio'] = features_df['new_listings'] / features_df['total_properties']\n",
        "        features_df['absorption_rate'] = features_df['closed_sales'] / features_df['active_listings']\n",
        "        features_df['off_market_rate'] = features_df['off_market'] / features_df['active_listings']\n",
        "\n",
        "        # Velocity Metrics\n",
        "        features_df['market_turnover'] = (features_df['closed_sales'] + features_df['pending_listings']) / features_df['total_properties']\n",
        "        features_df['pending_duration'] = features_df['days_on_market'] * 0.3  # Estimated pending time\n",
        "\n",
        "        # Supply-Demand Indicators\n",
        "        features_df['inventory_months'] = features_df['active_listings'] / (features_df['closed_sales'] / 3)\n",
        "        features_df['competition_index'] = features_df['pending_listings'] / features_df['active_listings']\n",
        "        features_df['market_pressure'] = (features_df['new_listings'] - features_df['closed_sales']) / features_df['new_listings']\n",
        "\n",
        "        # Market Heat Score (composite metric)\n",
        "        features_df['market_heat_score'] = (\n",
        "            (1 / features_df['inventory_months']) * 0.3 +\n",
        "            features_df['absorption_rate'] * 0.25 +\n",
        "            (1 / features_df['days_on_market']) * 0.2 +\n",
        "            features_df['pending_conversion_rate'] * 0.15 +\n",
        "            (1 - features_df['back_to_market_rate']) * 0.1\n",
        "        )\n",
        "\n",
        "        # Price Momentum Indicators (simulated)\n",
        "        features_df['price_momentum'] = np.where(\n",
        "            features_df['market_heat_score'] > features_df['market_heat_score'].median(),\n",
        "            np.random.normal(1.05, 0.1, len(features_df)),  # Rising prices\n",
        "            np.random.normal(0.98, 0.08, len(features_df))  # Falling prices\n",
        "        )\n",
        "\n",
        "        # Market Efficiency Metrics\n",
        "        features_df['listing_efficiency'] = features_df['closed_sales'] / features_df['new_listings']\n",
        "        features_df['market_velocity'] = features_df['total_properties'] / features_df['days_on_market']\n",
        "\n",
        "        # Handle infinite and NaN values\n",
        "        features_df = features_df.replace([np.inf, -np.inf], np.nan)\n",
        "        features_df = features_df.fillna(features_df.median())\n",
        "\n",
        "        return features_df\n",
        "\n",
        "    def prepare_features(self, df):\n",
        "        \"\"\"\n",
        "        Select and prepare final feature set for modeling\n",
        "        \"\"\"\n",
        "        feature_columns = [\n",
        "            'new_listings_ratio', 'absorption_rate', 'off_market_rate',\n",
        "            'market_turnover', 'pending_duration', 'inventory_months',\n",
        "            'competition_index', 'market_pressure', 'market_heat_score',\n",
        "            'price_momentum', 'listing_efficiency', 'market_velocity',\n",
        "            'days_on_market', 'pending_conversion_rate', 'back_to_market_rate'\n",
        "        ]\n",
        "\n",
        "        self.feature_names = feature_columns\n",
        "        return df[feature_columns]\n",
        "\n",
        "    def fit(self, X, y, optimize_hyperparameters=True):\n",
        "        \"\"\"\n",
        "        Train the XGBoost model with optional hyperparameter optimization\n",
        "        \"\"\"\n",
        "        print(\"üöÄ Training XGBoost Housing Market Prediction Model...\")\n",
        "\n",
        "        # Split data for validation\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_val_scaled = self.scaler.transform(X_val)\n",
        "\n",
        "        if optimize_hyperparameters:\n",
        "            print(\"üîß Optimizing hyperparameters...\")\n",
        "\n",
        "            # Define parameter grid for GridSearchCV\n",
        "            param_grid = {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'max_depth': [3, 4, 5, 6],\n",
        "                'learning_rate': [0.01, 0.1, 0.2],\n",
        "                'subsample': [0.8, 0.9, 1.0],\n",
        "                'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "                'reg_alpha': [0, 0.1, 0.5],\n",
        "                'reg_lambda': [1, 1.5, 2]\n",
        "            }\n",
        "\n",
        "            # Create XGBoost classifier\n",
        "            xgb_model = xgb.XGBClassifier(\n",
        "                objective='multi:softprob',\n",
        "                num_class=3,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "            # Perform grid search\n",
        "            grid_search = GridSearchCV(\n",
        "                xgb_model,\n",
        "                param_grid,\n",
        "                cv=5,\n",
        "                scoring='accuracy',\n",
        "                n_jobs=-1,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            grid_search.fit(X_train_scaled, y_train)\n",
        "            self.model = grid_search.best_estimator_\n",
        "\n",
        "            print(f\"‚úÖ Best parameters: {grid_search.best_params_}\")\n",
        "            print(f\"‚úÖ Best CV score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "        else:\n",
        "            # Use default optimized parameters\n",
        "            self.model = xgb.XGBClassifier(\n",
        "                objective='multi:softprob',\n",
        "                num_class=3,\n",
        "                n_estimators=200,\n",
        "                max_depth=4,\n",
        "                learning_rate=0.1,\n",
        "                subsample=0.9,\n",
        "                colsample_bytree=0.9,\n",
        "                reg_alpha=0.1,\n",
        "                reg_lambda=1.5,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Validate model\n",
        "        val_predictions = self.model.predict(X_val_scaled)\n",
        "        val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "        print(f\"‚úÖ Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Cross-validation score\n",
        "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5)\n",
        "        print(f\"‚úÖ Cross-validation Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "        self.is_fitted = True\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions on new data\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Model must be fitted before making predictions\")\n",
        "\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return self.model.predict(X_scaled)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Get prediction probabilities\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Model must be fitted before making predictions\")\n",
        "\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        return self.model.predict_proba(X_scaled)\n",
        "\n",
        "    def get_feature_importance(self, plot=True):\n",
        "        \"\"\"\n",
        "        Get and visualize feature importance\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Model must be fitted before getting feature importance\")\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_names,\n",
        "            'importance': self.model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        if plot:\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
        "            plt.title('Top 10 Feature Importance - XGBoost Housing Market Model')\n",
        "            plt.xlabel('Feature Importance')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        return importance_df\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Comprehensive model evaluation\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Model must be fitted before evaluation\")\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = self.predict(X_test)\n",
        "        y_pred_proba = self.predict_proba(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(\"üìä Model Evaluation Results:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred,\n",
        "                                  target_names=['Buyers Market', 'Even Market', 'Sellers Market']))\n",
        "\n",
        "        # Confusion Matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=['Buyers', 'Even', 'Sellers'],\n",
        "                   yticklabels=['Buyers', 'Even', 'Sellers'])\n",
        "        plt.title('Confusion Matrix - Housing Market Prediction')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'predictions': y_pred,\n",
        "            'probabilities': y_pred_proba\n",
        "        }\n",
        "\n",
        "    def interpret_prediction(self, X_sample, show_details=True):\n",
        "        \"\"\"\n",
        "        Interpret individual predictions with market insights\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Model must be fitted before making predictions\")\n",
        "\n",
        "        prediction = self.predict(X_sample)[0]\n",
        "        probabilities = self.predict_proba(X_sample)[0]\n",
        "\n",
        "        market_types = ['Buyers Market', 'Even Market', 'Sellers Market']\n",
        "        predicted_market = market_types[prediction]\n",
        "        confidence = probabilities[prediction]\n",
        "\n",
        "        if show_details:\n",
        "            print(f\"üè† Market Prediction: {predicted_market}\")\n",
        "            print(f\"üìà Confidence: {confidence:.2%}\")\n",
        "            print(\"\\nProbability Distribution:\")\n",
        "            for i, (market, prob) in enumerate(zip(market_types, probabilities)):\n",
        "                print(f\"  {market}: {prob:.2%}\")\n",
        "\n",
        "            # Market insights\n",
        "            sample_data = X_sample.iloc[0] if hasattr(X_sample, 'iloc') else X_sample[0]\n",
        "\n",
        "            print(f\"\\nüîç Key Market Indicators:\")\n",
        "            print(f\"  Inventory Months: {sample_data[5]:.1f}\")\n",
        "            print(f\"  Absorption Rate: {sample_data[1]:.2f}\")\n",
        "            print(f\"  Days on Market: {sample_data[12]:.0f}\")\n",
        "            print(f\"  Market Heat Score: {sample_data[8]:.2f}\")\n",
        "\n",
        "        return {\n",
        "            'prediction': prediction,\n",
        "            'market_type': predicted_market,\n",
        "            'confidence': confidence,\n",
        "            'probabilities': dict(zip(market_types, probabilities))\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "imRKtoJEzTMe",
        "outputId": "1b4389ae-390a-469d-fc4b-11efb16e3f4b"
      },
      "outputs": [],
      "source": [
        "# Example usage and complete workflow\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Complete example of using the Housing Market Predictor\n",
        "    \"\"\"\n",
        "    print(\"üè° Housing Market Prediction with XGBoost\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize the predictor\n",
        "    predictor = HousingMarketPredictor()\n",
        "\n",
        "    # Generate sample data\n",
        "    print(\"üìä Generating sample housing market data...\")\n",
        "    raw_data = predictor.create_sample_data(n_samples=2000)\n",
        "    print(f\"Generated {len(raw_data)} samples\")\n",
        "\n",
        "    # Engineer features\n",
        "    print(\"üîß Engineering features...\")\n",
        "    featured_data = predictor.engineer_features(raw_data)\n",
        "\n",
        "    # Prepare features and target\n",
        "    X = predictor.prepare_features(featured_data)\n",
        "    y = featured_data['market_condition']\n",
        "\n",
        "    print(f\"Feature matrix shape: {X.shape}\")\n",
        "    print(f\"Target distribution:\\n{y.value_counts().sort_index()}\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    predictor.fit(X_train, y_train, optimize_hyperparameters=False)  # Set to True for full optimization\n",
        "\n",
        "    # Evaluate model\n",
        "    results = predictor.evaluate_model(X_test, y_test)\n",
        "\n",
        "    # Feature importance\n",
        "    importance_df = predictor.get_feature_importance(plot=True)\n",
        "    print(\"\\nTop 5 Most Important Features:\")\n",
        "    print(importance_df.head())\n",
        "\n",
        "    # Example prediction\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üîÆ Example Market Prediction:\")\n",
        "    sample_data = X_test.iloc[:1]\n",
        "    actual_market = ['Buyers Market', 'Even Market', 'Sellers Market'][y_test.iloc[0]]\n",
        "\n",
        "    print(f\"Actual Market: {actual_market}\")\n",
        "    prediction_result = predictor.interpret_prediction(sample_data)\n",
        "\n",
        "    return predictor, results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the complete example\n",
        "    model, evaluation_results = main()\n",
        "\n",
        "    print(\"\\nüéâ Model training and evaluation completed successfully!\")\n",
        "    print(f\"Final Model Accuracy: {evaluation_results['accuracy']:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
